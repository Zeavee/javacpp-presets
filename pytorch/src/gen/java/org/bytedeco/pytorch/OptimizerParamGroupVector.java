// Targeted by JavaCPP version 1.5.7: DO NOT EDIT THIS FILE

package com.oracle.svm.shadowed.org.bytedeco.pytorch;

import com.oracle.svm.shadowed.org.bytedeco.pytorch.Allocator;
import com.oracle.svm.shadowed.org.bytedeco.pytorch.Function;
import com.oracle.svm.shadowed.org.bytedeco.pytorch.Module;
import java.nio.*;
import com.oracle.svm.shadowed.org.bytedeco.javacpp.*;
import com.oracle.svm.shadowed.org.bytedeco.javacpp.annotation.*;

import static com.oracle.svm.shadowed.org.bytedeco.javacpp.presets.javacpp.*;
import static com.oracle.svm.shadowed.org.bytedeco.openblas.global.openblas_nolapack.*;
import static com.oracle.svm.shadowed.org.bytedeco.openblas.global.openblas.*;

import static com.oracle.svm.shadowed.org.bytedeco.pytorch.global.torch.*;

@Name("std::vector<torch::optim::OptimizerParamGroup>") @Properties(inherit = com.oracle.svm.shadowed.org.bytedeco.pytorch.presets.torch.class)
public class OptimizerParamGroupVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OptimizerParamGroupVector(Pointer p) { super(p); }
    public OptimizerParamGroupVector()       { allocate();  }
    private native void allocate();


    public boolean empty() { return size() == 0; }
    public native long size();

    @Index(function = "at") public native @ByRef OptimizerParamGroup get(@Cast("size_t") long i);

    public native @ByVal Iterator begin();
    public native @ByVal Iterator end();
    @NoOffset @Name("iterator") public static class Iterator extends Pointer {
        public Iterator(Pointer p) { super(p); }
        public Iterator() { }

        public native @Name("operator ++") @ByRef Iterator increment();
        public native @Name("operator ==") boolean equals(@ByRef Iterator it);
        public native @Name("operator *") @ByRef @Const OptimizerParamGroup get();
    }
}

